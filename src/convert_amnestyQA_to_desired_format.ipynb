{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# this will convert the AmnestyQA dataset\n",
        "# https://huggingface.co/datasets/explodinggradients/amnesty_qa/blob/main/english.json\n",
        "# to the desired format that we are using in the competition\n",
        "# https://github.com/sujitpal/llm-rag-eval\n",
        "#\n",
        "# download the above json file to a file local to this notebook\n",
        "# (i had trouble reading this directly online - https://huggingface.co/datasets/explodinggradients/amnesty_qa/raw/main/english.json)"
      ],
      "metadata": {
        "id": "TuhTbzYKIqGG"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "XRqK1t_l0g7_"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "# input file\n",
        "input_file_path = 'english.json'\n",
        "# output file\n",
        "output_file_path = 'amnesty_qa.jsonl'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_newlines(input_string):\n",
        "    \"\"\"Split the input string at newline characters and return a list of strings.\"\"\"\n",
        "    if '\\n' in input_string:\n",
        "        return input_string.split('\\n')\n",
        "    else:\n",
        "        return [input_string]"
      ],
      "metadata": {
        "id": "wECIVkMrl_r_"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Opening the JSON file and loading the data\n",
        "with open(input_file_path, 'r') as file:\n",
        "    data = json.load(file)"
      ],
      "metadata": {
        "id": "piVFXu0Z0zL9"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the data is not nested / folded\n",
        "# so each of components is read in and the output folding happens next\n",
        "questions = data.get('question')\n",
        "ground_truths = data.get('ground_truths')\n",
        "answers = data.get('answer')\n",
        "contexts = data.get('contexts')"
      ],
      "metadata": {
        "id": "hjIQKOEr0_dQ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# output will be lines\n",
        "lines = []"
      ],
      "metadata": {
        "id": "Et8TapVb4pjj"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assemble from the nth item from each component list\n",
        "# blow out the multi-line contexts into single line chunk dictionaries\n",
        "for i in range(len(questions)):\n",
        "  line = {}\n",
        "  line['id'] = i\n",
        "  line['query'] = questions[i]\n",
        "  context_list = []\n",
        "  split_contexts = split_newlines(contexts[i][0])\n",
        "  for j in range(len(split_contexts)):\n",
        "    context_dict = {}\n",
        "    context_dict['id'] = str(j)\n",
        "    context_dict['chunk_text'] = split_contexts[j]\n",
        "    context_list.append(context_dict)\n",
        "  line['context'] = context_list\n",
        "  line['ideal_answer'] = ground_truths[i][0]\n",
        "  line['predicted_answer'] = answers[i]\n",
        "  lines.append(line)"
      ],
      "metadata": {
        "id": "T5d9q2Jo1I9l"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# write the lines to the output file\n",
        "with open(output_file_path, 'w') as outfile:\n",
        "    for dictionary in lines:\n",
        "        json_line = json.dumps(dictionary)  # Convert the dictionary to a JSON string\n",
        "        outfile.write(json_line + '\\n')  # Write the JSON string to the file and add a newline"
      ],
      "metadata": {
        "id": "CF7_eK3A1w20"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CK2v4BF4rmwp"
      },
      "execution_count": 36,
      "outputs": []
    }
  ]
}